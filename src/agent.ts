// agent.mts - Main LangGraph agent with MCP tools integration

// Load environment variables from .env file
import "dotenv/config";

import { TavilySearch } from "@langchain/tavily";
import { ChatOpenAI } from "@langchain/openai";
import {
    AIMessage,
    HumanMessage,
    SystemMessage,
} from "@langchain/core/messages";
import { ToolNode } from "@langchain/langgraph/prebuilt";
import { MessagesAnnotation, StateGraph } from "@langchain/langgraph";
import { writeFileSync } from "node:fs";
import { mcpTools } from "./tools/mcpTools";

// Define the tools for the agent to use
const tools = [new TavilySearch({ maxResults: 3 }), ...mcpTools];
const toolNode = new ToolNode(tools);

const model = new ChatOpenAI({
    model: "gpt-4o-mini",
    temperature: 0,
}).bindTools(tools);

// function that determines whether to continue or not
function shouldContinue({ messages }: typeof MessagesAnnotation.State) {
    const lastMessage = messages[messages.length - 1] as AIMessage;

    if (lastMessage.tool_calls?.length) {
        return "tools";
    }
    return "__end__";
}

const systemMessageText =
    "Jsi uÅ¾iteÄnÃ½ asistent, kterÃ½ komunikuje s uÅ¾ivateli VÃHRADNÄš V ÄŒEÅ TINÄš!" +
    "RadÃ­Å¡ uÅ¾ivatelÅ¯m s recepty a jsi schopnÃ½ tÄ›chto ÃºkonÅ¯:" +
    "- pÅ™idÃ¡vat a odebÃ­rat ingredience z nÃ¡kupnÃ­ho seznamu" +
    "- vyhledÃ¡vat recepty podle diety nebo typu jÃ­dla" +
    "- plÃ¡novat jÃ­delnÃ­Äek na vÃ­ce dnÃ­ podle dietnÃ­ch poÅ¾adavkÅ¯ uÅ¾ivatele" +
    "\n\nKdyÅ¾ vytvÃ¡Å™Ã­Å¡ jÃ­delnÃ­Äek, VÅ½DY ho prezentuj v tomto formÃ¡tu:" +
    "\nğŸ“… JÃDELNÃÄŒEK:" +
    "\nğŸ—“ï¸ Den 1 (pondÄ›lÃ­):" +
    "\n  â€¢ SnÃ­danÄ›: [nÃ¡zev receptu]" +
    "\n  â€¢ ObÄ›d: [nÃ¡zev receptu]" +
    "\n  â€¢ VeÄeÅ™e: [nÃ¡zev receptu]" +
    "\nğŸ—“ï¸ Den 2 (ÃºterÃ½):" +
    "\n  â€¢ SnÃ­danÄ›: [nÃ¡zev receptu]" +
    "\n  â€¢ atd..." +
    "\n\nVÅ¾dy pÅ™idej vÅ¡echny ingredience z vybranÃ½ch receptÅ¯ na nÃ¡kupnÃ­ seznam.";

async function callModel(state: typeof MessagesAnnotation.State) {
    const systemMessage = new SystemMessage(systemMessageText);
    const messagesWithSystem = [systemMessage, ...state.messages];
    const response = await model.invoke(messagesWithSystem);
    return { messages: [response] };
}

const workflow = new StateGraph(MessagesAnnotation)
    .addNode("agent", callModel)
    .addEdge("__start__", "agent")
    .addNode("tools", toolNode)
    .addEdge("tools", "agent")
    .addConditionalEdges("agent", shouldContinue);

const app = workflow.compile();

export { app };

"""
Main LangGraph agent with MCP tools integration - Python version
"""
import os
from typing import Literal
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage, SystemMessage
from langgraph.prebuilt import ToolNode
from langgraph.graph import MessagesState, StateGraph, START, END
from src.tools.mcp_tools import mcp_tools

# Load environment variables from .env file (standard Python way)
load_dotenv()

# Define the tools for the agent to use - only MCP tools for recipe focus
tools = mcp_tools
tool_node = ToolNode(tools)

# Initialize the model
model = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0,
).bind_tools(tools)

def should_continue(state: MessagesState) -> Literal["tools", "__end__"]:
    """
    Determines the next action based on the last message in the conversation.
    
    If the last message contains tool calls, returns "tools" to indicate that 
    tool processing should continue. Otherwise, returns "__end__" to signal 
    the end of the process.
    """
    messages = state["messages"]
    last_message = messages[-1]
    
    if isinstance(last_message, AIMessage) and last_message.tool_calls:
        return "tools"
    return "__end__"

# System message in Czech
SYSTEM_MESSAGE_TEXT = (
    "Jsi uÅ¾iteÄnÃ½ asistent, kterÃ½ komunikuje s uÅ¾ivateli VÃHRADNÄš V ÄŒEÅ TINÄš! "
    "RadÃ­Å¡ uÅ¾ivatelÅ¯m s recepty a jsi schopnÃ½ tÄ›chto ÃºkonÅ¯: "
    "- pÅ™idÃ¡vat a odebÃ­rat ingredience z nÃ¡kupnÃ­ho seznamu "
    "- vyhledÃ¡vat recepty podle diety nebo typu jÃ­dla pomocÃ­ MCP serveru "
    "- plÃ¡novat jÃ­delnÃ­Äek na vÃ­ce dnÃ­ podle dietnÃ­ch poÅ¾adavkÅ¯ uÅ¾ivatele "
    "- vytvÃ¡Å™et strukturovanÃ½ pÅ™ehled jÃ­delnÃ­Äku "
    "\n\nPro vyhledÃ¡vÃ¡nÃ­ receptÅ¯ pouÅ¾Ã­vej nÃ¡stroje search_recipes a get_all_recipes. "
    "Pokud nenajdeÅ¡ recepty pro specifickou dietu, navrhni alternativy z dostupnÃ½ch receptÅ¯. "
    "\n\nKdyÅ¾ vytvÃ¡Å™Ã­Å¡ jÃ­delnÃ­Äek, VÅ½DY ho prezentuj v tomto formÃ¡tu: "
    "\nðŸ“… JÃDELNÃÄŒEK: "
    "\nðŸ—“ï¸ Den 1: "
    "\n  â€¢ SnÃ­danÄ›: [nÃ¡zev receptu] "
    "\n  â€¢ ObÄ›d: [nÃ¡zev receptu] "
    "\n  â€¢ VeÄeÅ™e: [nÃ¡zev receptu] "
    "\nðŸ—“ï¸ Den 2: "
    "\n  â€¢ SnÃ­danÄ›: [nÃ¡zev receptu] "
    "\n  â€¢ atd... "
    "\n\nVÅ¾dy pÅ™idej vÅ¡echny ingredience z vybranÃ½ch receptÅ¯ na nÃ¡kupnÃ­ seznam. "
    "\nVÅ¡e na co odpovÃ­dÃ¡Å¡ se pÃ­Å¡e do bash konzole, formÃ¡tuj odpovÄ›di podle toho (nepouÅ¾Ã­vej markdown formÃ¡tovÃ¡nÃ­)"
)

def call_model(state: MessagesState) -> dict:
    """
    Invokes the model with the current state messages, prepending a system message.
    """
    messages = state["messages"]
    system_message = SystemMessage(content=SYSTEM_MESSAGE_TEXT)
    messages_with_system = [system_message] + messages
    
    response = model.invoke(messages_with_system)
    return {"messages": [response]}

# Create the workflow
workflow = StateGraph(MessagesState)

# Add nodes
workflow.add_node("agent", call_model)
workflow.add_node("tools", tool_node)

# Add edges
workflow.add_edge(START, "agent")
workflow.add_edge("tools", "agent")
workflow.add_conditional_edges("agent", should_continue)

# Compile the app with recursion limit
app = workflow.compile()

async def create_agent():
    """Create and return the configured agent"""
    return app
